import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import SGD
import numpy as np
from time import time
import torch
import datetime
from matplotlib import pyplot as plt
from sklearn.metrics import mean_squared_error
import SampleData


class TensorFlow():
    def __init__(self, train_data, test_data):
        self.train_data = train_data
        self.test_data = test_data
        self.model = 0

    def train(self):
        # Training Data (Preprocessing)
        xs_train = tf.convert_to_tensor(
            self.train_data[0], dtype=tf.int64)
        ys_train = tf.convert_to_tensor(
            self.train_data[1], dtype=tf.int64)

        # Exploration
        #plt.plot(xs_train, ys_train)
        # plt.show()

        # Training Parameters
        learning_rate = 0.001
        n_epochs = 25

        # Initializing Model
        self.model = keras.Sequential(
            [keras.layers.Dense(units=1, input_shape=[1])])

        # Define Optimizer
        opt = tf.keras.optimizers.Adam(lr=learning_rate)

        self.model.compile(
            optimizer=opt, loss='mean_squared_error')

        # Callback f√ºr TensorBoard
        log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        tensorboard_callback = tf.keras.callbacks.TensorBoard(
            log_dir=log_dir,
            histogram_freq=1,
            profile_batch='500,520'
        )

        # Modelfitting
        start_training = time()
        history = self.model.fit(xs_train, ys_train, validation_split=0.33, epochs=n_epochs, callbacks=[
                                 tensorboard_callback])
        end_training = time()

        # Time
        duration_training = end_training - start_training

        print('------ TensorFlow ------')
        print(f'Duration Training: {duration_training} seconds')

        # summarize history for loss
        plt.plot(history.history['loss'], 'blue')
        plt.plot(history.history['val_loss'], 'red')
        plt.title('model loss')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'test'], loc='upper right')
        plt.show()

    def test(self):
       # Test Data (Preprocessing)
        xs_test = tf.convert_to_tensor(self.test_data[0], dtype=tf.int64)
        ys_test = tf.convert_to_tensor(self.test_data[1], dtype=tf.int64)

        # Predict Data
        start_test = time()
        y_pred = self.model.predict(xs_test)
        end_test = time()

        # Time
        duration_test = end_test - start_test

        print(f'Duration Inference: {duration_test} seconds')

        # MSE (Mean Squarred Error)
        mse = mean_squared_error(ys_test, y_pred)
        print('Mean squared error: ', mse)

        return duration_test, mse

    # Parameter (zB Learning Rate (min-max in 10 Schritten), Anzahl Layer, Anzahl Epochen) aus JSON Konfigurationsfile laden
    # 1. Funktion: Training, return: Accuracy, Time
    # 2. Funktion Inferenz, return: Time
    # Varianz-Bias Trade off
    # Funktion in TensorFlow: Trainings, Testfehler ausgeben
    # Plots: Trainingsdaten, Testdaten, Accuracy vs Rechenzeit, Overfitting-plot
    # Weitere Modelle trainieren
    # Classcompliance
